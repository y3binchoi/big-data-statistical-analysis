{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습에필요한패키지불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째(sepal length)와세번째(petal length) 변수만추출하여 x로할당\n",
    "x = iris.data[:, [0, 2]]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습자료와 검증자료 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화(평균0, 표준편차 1) \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc= StandardScaler()\n",
    "sc.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## numpy.ndarray 형식으로 출력\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_std의평균과 표준편차\n",
    "print('Mean of x_train_std:',np.mean(x_train_std[:,0]), np.mean(x_train_std[:,1]))\n",
    "print('Stdof x_train_std:',np.std(x_train_std[:,0]), np.std(x_train_std[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C가 작은 경우(오분류를 관대하게 허용)\n",
    "# SVC 클래스에 kernel='linear', 시드넘버는1, C=0.1로 설정\n",
    "from sklearn.svm import SVC\n",
    "svm_smallc= SVC(kernel='linear', random_state=1, C=0.1)\n",
    "svm_smallc.fit(x_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화된 것과 안된 것\n",
    "x_combined_std= np.vstack((x_train_std, x_test_std))\n",
    "y_combined= np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터와 결정경계그림\n",
    "# !pip install mlxtend\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "plot_decision_regions(x_combined_std, y_combined, clf=svm_smallc)\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값과 관측값 비교\n",
    "y_pred= svm_smallc.predict(x_test_std)\n",
    "y_pred,(y_test!= y_pred)\n",
    "print('Misclassified samples: %d' % (y_test!= y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 계산\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C가 큰 경우(오분류를 엄격하게 허용)\n",
    "# SVC 클래스에kernel='linear', 시드넘버는1, C=10로 설정\n",
    "svm_largec= SVC(kernel='linear', random_state=1, C=10)\n",
    "svm_largec.fit(x_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터와 결정경계그림\n",
    "plot_decision_regions(x_combined_std, y_combined, clf=svm_largec)\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값과 관측값 비교\n",
    "y_pred= svm_largec.predict(x_test_std)\n",
    "y_pred,(y_test!= y_pred)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test!= y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정확도 계산\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel SVM : Gamma의값에 따른 결정경계면의 변화\n",
    "# gamma가작을때: 1\n",
    "# SVC 클래스에kernel='rbf', 시드넘버는1, gamma=1로 설정\n",
    "svm_k_smallg= SVC(kernel='rbf', random_state=1, gamma=1)\n",
    "svm_k_smallg.fit(x_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터와 결정경계그림\n",
    "plot_decision_regions(x_combined_std, y_combined, clf=svm_k_smallg)\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값과 관측값 비교\n",
    "y_pred= svm_k_smallg.predict(x_test_std)\n",
    "y_pred,(y_test!= y_pred)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test!= y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 계산\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel SVM : Gamma의값에 따른 결정경계면의 변화\n",
    "# gamma가클때: 100\n",
    "# SVC 클래스에kernel='rbf', 시드넘버는1, gamma=100로 설정\n",
    "svm_k_largeg= SVC(kernel='rbf', random_state=1, gamma=100)\n",
    "svm_k_largeg.fit(x_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터와 결정경계그림\n",
    "plot_decision_regions(x_combined_std, y_combined, clf=svm_k_largeg)\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값과 관측값 비교\n",
    "y_pred= svm_k_largeg.predict(x_test_std)\n",
    "y_pred,(y_test!= y_pred)\n",
    "print('Misclassified samples: %d' % (y_test!= y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 계산\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitedata = pd.read_csv(\"white.csv\") \n",
    "X = whitedata.drop([\"y\"],axis=1)\n",
    "y = whitedata[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Support Vector Regression model\n",
    "- kernel : 선형 커널\n",
    "- C : 학습 오류에 대한 패널티, C 값이 클 수록 모델이 학습 데이터에 좀 더 최적화 됨, 너무 크면 오버피팅 발생\n",
    "- Epsilon : 임계값, 예측한 값이 GT 범위 안에 있으면 패널티 부여 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "sv_regressor = SVR(kernel='linear', C=1.0, epsilon=0.1)\n",
    "sv_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sv_regressor.predict(X_test)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "print(\"MSE:\",mse)\n",
    "print(\"EVS:\",evs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
